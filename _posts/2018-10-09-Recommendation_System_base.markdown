---
layout:     post
title:      "推荐系统-基础概念概述"
subtitle:   " \"推荐系统-基础概念概述\""
date:       2018-10-09 14:46
header-img: "img/post-bg-ai.jpg" 
author:     "pepperliu"
catalog:      true
tags:
    - ai
    - recommendation\_system
---

> 在浏览网页时经常会遇到信息过载的问题，这时需要一个工具来帮助你做筛选，它可以分析你的历史兴趣，从庞大的电影库中找到几部符合你兴趣的电影供你选择。这个工具就是推荐系统

### 1. 协同过滤

在讲解协同过滤之前，我们先考虑如下几个问题：

- 如果你现在想看个电影，但你不知道具体看哪部，你会怎么做?
- 如何确定一个用户是不是和你有相似的品位?
- 如何将邻居们的喜好组织成一个排序的目录?

协同过滤就是用来解决上述问题的，实现协同过滤的步骤如下：

1. 收集用户偏好
2. 找到相似的用户或物品
3. 计算推荐

![image](https://blog.lpc-win32.com/img/2018-10-09/01.png)

#### 1.1 基于用户的协同过滤

![image](https://blog.lpc-win32.com/img/2018-10-09/02.png)

1. 在用户中找相似用户
2. 根据相似用户的行为进行推荐

基于用户协同过滤需要解决的问题：

- 已知用户评分矩阵Matrix R（通常都是非常稀疏的）
- 推断矩阵中空格empty cells处的值

- 对于一个新用户，很难找到邻居用户（新用户往往所有的向量都是0）
- 对于一个物品，所有最近的邻居在其上打分

基础解决方案如下：

- 相似度计算最好使用皮尔逊相似度
- 考虑到共同打分物品的数目，如乘上min(n,N)/N - n->共同打分数 N->指定阈值
- 对比打分进行归一化处理
- 设置一个相似度阈值

基于用户的协同过滤为什么不流行？

1. 稀疏问题
2. 数百万的用户计算，量级过大
3. 人是善变的，导致推荐会产生偏差

#### 1.2 基于物品的协同过滤（使用的比较多）

基于物品做协同过滤的优势：

1. 计算性能高，通常用户量级大于物品量级
2. 可预先计算保留，物品不善变

![image](https://blog.lpc-win32.com/img/2018-10-09/03.png)

![image](https://blog.lpc-win32.com/img/2018-10-09/04.png)

#### 1.3 冷启动问题

用户冷启动问题：

- 引导用户把自己的一些属性表达出大
- 利用现有的开放数据平台
- 用户注册属性
- 推荐排行榜单（大众心理）

物品冷启动问题：

- 文本分析
- 主题模型
- 打标签
- 推荐排行榜单

#### 1.4 UserCF与ItemCF对比

![image](https://blog.lpc-win32.com/img/2018-10-09/05.png)

基于用户的推荐：

- 实时新闻
- 突然情况

基于物品的推荐：

- 图书
- 电子商务
- .......

#### 1.5 相似度计算

![image](https://blog.lpc-win32.com/img/2018-10-09/11.png)

- 欧几里德距离(Euclidean Distance)
- 皮尔逊相关系数(Pearson Correlation Coefficient)
- Cosine 相似度(Cosine Similarity)

![image](https://blog.lpc-win32.com/img/2018-10-09/12.png)

##### 1.5.1 皮尔逊相关系数

![image](https://blog.lpc-win32.com/img/2018-10-09/13.png)

![image](https://blog.lpc-win32.com/img/2018-10-09/14.png)

##### 1.5.2 邻居的选择

- A.固定数量的邻居
- B.基于相似度门槛的邻居

![image](https://blog.lpc-win32.com/img/2018-10-09/15.png)

### 2. 隐语义模型

- 从数据出发，进行个性化推荐
- 用户和物品之间有着隐含的联系
- 隐含因子让计算机能够理解就好
- 讲用户和物品通过中介隐含因子联系起来

> 找到物体之间的隐含关联（隐含因子）

**隐语义的核心思想：通过多个稀疏矩阵还原成相对密集的矩阵，分解与组合**

![image](https://blog.lpc-win32.com/img/2018-10-09/06.png)

#### 2.1 隐语义模型求解

![image](https://blog.lpc-win32.com/img/2018-10-09/07.png)

上图可知：用户乘上隐含因子得到的关系与物品乘上隐含因子得到的关系

![image](https://blog.lpc-win32.com/img/2018-10-09/08.png)

隐语义模型负样本选择：

- 对于每个用户，要保证正负样本的平衡（数目相似）
- 选取那些很热门，而用户却没有行为的物品
- 对于用户-物品集K{(u,i)}，其中(u,i)是正样本，则有rui \= 1,负样本rui \= 0

隐语义模型参数选择：

- 隐特性的个数F，通常F=100（设置过大建模时间会长）
- 学习速率alpha，别太大
- 正则化参数lambda，别太大
- 负样本/正样本比例ratio

![image](https://blog.lpc-win32.com/img/2018-10-09/09.png)

### 3.协同过滤VS隐语义

- 原理：协同过滤基于统计，隐语义基于建模
- 空间复杂度，隐语义模型较小
- 实时推荐依旧很难，目前离线计算多

### 4. 模型评估标准

- 准确度与召回率：最重要的指标，推荐的效果是否好
- 覆盖率：推荐的广度
- 多样性：推荐信息的多样性

![image](https://blog.lpc-win32.com/img/2018-10-09/10.png)

核心考虑的问题：

- 推荐好坏的评估
- 模型量级问题
